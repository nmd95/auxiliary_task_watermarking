{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"conver_ckpt_to_st_dict.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KsNsx__4Lt71","executionInfo":{"status":"ok","timestamp":1625662282649,"user_tz":-180,"elapsed":282,"user":{"displayName":"Barak Levy","photoUrl":"","userId":"11917179774666865192"}},"outputId":"5823c0b5-3dce-4fb0-a804-36baa3f47e4b"},"source":["%cd /content/drive/MyDrive/amnlp_project_round_2"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/amnlp_project_round_2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C8L2yan5L2p_","executionInfo":{"status":"ok","timestamp":1625662287150,"user_tz":-180,"elapsed":2007,"user":{"displayName":"Barak Levy","photoUrl":"","userId":"11917179774666865192"}}},"source":["import tensorflow as tf\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V7S1cHb_PiG5","executionInfo":{"status":"ok","timestamp":1625660668413,"user_tz":-180,"elapsed":2441,"user":{"displayName":"Water Mark","photoUrl":"","userId":"04144044596634907719"}},"outputId":"e34a8647-3e42-438d-dbaf-3d0caac76f2b"},"source":["# with tf.compat.v1.Session() as sess:\n","#     saver = tf.compat.v1.train.import_meta_graph('/content/drive/MyDrive/amnlp_project_round_2/seed_4/bert.ckpt.meta')\n","#     saver.restore(sess, \"/content/drive/MyDrive/amnlp_project_round_2/seed_4/bert.ckpt\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/amnlp_project_round_2/seed_4/bert.ckpt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YUE-_Yu-QfJ-"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7zra1ClBVpwO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625663568436,"user_tz":-180,"elapsed":13023,"user":{"displayName":"Barak Levy","photoUrl":"","userId":"11917179774666865192"}},"outputId":"56abbfbb-fa41-4180-bc8c-c301c67c7879"},"source":["!export BERT_BASE_DIR=/content/drive/MyDrive/amnlp_project_round_2/seed_7\n","\n","!transformers-cli convert --model_type bert \\\n","  --tf_checkpoint /content/drive/MyDrive/amnlp_project_round_2/seed_7/bert.ckpt \\\n","  --config /content/drive/MyDrive/amnlp_project_round_2/seed_4/public_bert_config.json \\\n","  --pytorch_dump_output $BERT_BASE_DIR/pytorch_model_7.bin"],"execution_count":16,"outputs":[{"output_type":"stream","text":["2021-07-07 13:12:37.294725: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Building PyTorch model from configuration: BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.8.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Converting TensorFlow checkpoint from /content/drive/MyDrive/amnlp_project_round_2/seed_7/bert.ckpt\n","Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n","Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n","Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n","Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n","2021-07-07 13:12:42.232665: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 93763584 exceeds 10% of free system memory.\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n","Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n","Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n","Loading TF weight bert/pooler/dense/bias with shape [768]\n","Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n","Loading TF weight cls/predictions/output_bias with shape [30522]\n","Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n","Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n","Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n","Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n","Loading TF weight cls/seq_relationship/output_bias with shape [2]\n","Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n","Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n","Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n","Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n","Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n","Save PyTorch model to /pytorch_model_7.bin\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kOmRrrAa_0nj"},"source":["# # /bin/bash\n","# !for ckpt in {0..24} ; do\n","#   !wget \"https://storage.googleapis.com/multiberts/public/models/seed_${ckpt}.zip\"\n","#   !unzip \"seed_${ckpt}.zip\"\n","# done\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZleCQ5khARhe"},"source":["# for ckpt in range(1,24) ; do\n","#   !wget f\"https://storage.googleapis.com/multiberts/public/models/seed_${ckpt}.zip\"\n","#   !unzip f\"seed_${ckpt}.zip\"\n","# done\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lA40E4SlXS3J"},"source":["--config /content/drive/MyDrive/amnlp_project_round_2/seed_4/bert_config.json \\"],"execution_count":null,"outputs":[]}]}